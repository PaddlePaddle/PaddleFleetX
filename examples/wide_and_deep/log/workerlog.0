server not ready, wait 3 sec to retry...
not ready endpoints:['127.0.0.1:10095']
!!! The CPU_NUM is not specified, you should set CPU_NUM in the environment variable list.
CPU_NUM indicates that how many CPUPlace are used in the current task.
And if this parameter are set as N (equal to the number of physical CPU core) the program may be faster.

export CPU_NUM=48 # for example, set CPU_NUM as number of physical CPU core which is 48.

!!! The default number of CPU_NUM=1.
TRAIN ---> pass: 0 loss: 0.6685048937797546

TRAIN ---> pass: 0 loss: 0.6323686838150024

TRAIN ---> pass: 0 loss: 0.6174567937850952

TRAIN ---> pass: 0 loss: 0.6854206919670105

TRAIN ---> pass: 0 loss: 0.7380686402320862

TRAIN ---> pass: 0 loss: 0.6331899762153625

TRAIN ---> pass: 0 loss: 0.5688082575798035

TRAIN ---> pass: 0 loss: 0.6567495465278625

TRAIN ---> pass: 0 loss: 0.6847177147865295

TRAIN ---> pass: 0 loss: 0.6119033098220825

TRAIN ---> pass: 0 loss: 0.666806697845459

TRAIN ---> pass: 0 loss: 0.6299632787704468

TRAIN ---> pass: 0 loss: 0.6159160733222961

TRAIN ---> pass: 0 loss: 0.683138370513916

TRAIN ---> pass: 0 loss: 0.738569438457489

TRAIN ---> pass: 0 loss: 0.6328006982803345

TRAIN ---> pass: 0 loss: 0.5670680999755859

TRAIN ---> pass: 0 loss: 0.6554805040359497

TRAIN ---> pass: 0 loss: 0.6857677698135376

TRAIN ---> pass: 0 loss: 0.610797643661499

/opt/conda/envs/py37/lib/python3.7/site-packages/paddle/distributed/fleet/utils/ps_util.py:199: UserWarning: lookup_table will be forced to test mode when use DistributedInfer
  "lookup_table will be forced to test mode when use DistributedInfer"
TEST ---> loss: 0.6648499369621277 auc: 0.375 acc: 0.800000011920929 mae: 0.24126839637756348, mse: 0.0787191241979599 rmse: 0.28056928515434265

TEST ---> loss: 0.6271860599517822 auc: 0.47058823529411764 acc: 0.42500001192092896 mae: 0.18928615748882294, mse: 0.07559395581483841 rmse: 0.2749435603618622

TEST ---> loss: 0.6141164302825928 auc: 0.48 acc: 0.3571428656578064 mae: 0.17437641322612762, mse: 0.07403803616762161 rmse: 0.2720993161201477

TEST ---> loss: 0.6804285049438477 auc: 0.4901960784313726 acc: 0.3400000035762787 mae: 0.17135904729366302, mse: 0.0758286714553833 rmse: 0.2753700613975525

TEST ---> loss: 0.7387658357620239 auc: 0.4498834498834499 acc: 0.30000001192092896 mae: 0.1714601367712021, mse: 0.07878866791725159 rmse: 0.2806932032108307

/opt/conda/envs/py37/lib/python3.7/site-packages/paddle/distributed/fleet/base/role_maker.py:314: UserWarning: gloo is not initialized, will not communicator with other nodes
  warnings.warn(self._err_init)
Global Metrics ---> average loss: [0.36938292] global auc: 0.44988344988344986 global acc: 0.26 global mae: 0.1600294621785482 global mse: 0.07878866831461588 global rmse: 0.2806931924978158

TEST ---> loss: 0.6325856447219849 auc: 0.5051851851851852 acc: 0.28125 mae: 0.16804824769496918, mse: 0.078145332634449 rmse: 0.279544860124588

TEST ---> loss: 0.566603422164917 auc: 0.5504994450610433 acc: 0.2789473831653595 mae: 0.16412176191806793, mse: 0.07603998482227325 rmse: 0.2757534980773926

TEST ---> loss: 0.6551538705825806 auc: 0.5700000000000001 acc: 0.27272728085517883 mae: 0.16347450017929077, mse: 0.07617457211017609 rmse: 0.2759974002838135

TEST ---> loss: 0.6857432126998901 auc: 0.5733173076923077 acc: 0.25600001215934753 mae: 0.16351711750030518, mse: 0.07687383890151978 rmse: 0.27726131677627563

TEST ---> loss: 0.6106315851211548 auc: 0.5898494414764449 acc: 0.25357142090797424 mae: 0.16204476356506348, mse: 0.07631947845220566 rmse: 0.27625980973243713

Global Metrics ---> average loss: [0.3053158] global auc: 0.5898494414764449 global acc: 0.23666666666666666 global mae: 0.15664326985677082 global mse: 0.07631947835286458 global rmse: 0.2762598022747149

TEST ---> loss: 0.6648499369621277 auc: 0.5702327480604328 acc: 0.2548387050628662 mae: 0.1619323343038559, mse: 0.07653763145208359 rmse: 0.27665436267852783

TEST ---> loss: 0.6271860599517822 auc: 0.5754616477272727 acc: 0.25882354378700256 mae: 0.16130653023719788, mse: 0.07619855552911758 rmse: 0.27604085206985474

TEST ---> loss: 0.6141164302825928 auc: 0.5739889705882353 acc: 0.2594594657421112 mae: 0.16037656366825104, mse: 0.07579299062490463 rmse: 0.27530527114868164

TEST ---> loss: 0.6804285049438477 auc: 0.5680272108843538 acc: 0.26249998807907104 mae: 0.16059140861034393, mse: 0.07617924362421036 rmse: 0.2760058641433716

TEST ---> loss: 0.7387658357620239 auc: 0.5497727272727273 acc: 0.25581395626068115 mae: 0.16135773062705994, mse: 0.07714253664016724 rmse: 0.27774545550346375

Global Metrics ---> average loss: [0.36938292] global auc: 0.5497727272727273 global acc: 0.24444444444444444 global mae: 0.1577719963921441 global mse: 0.07714253743489584 global rmse: 0.277745454391059

TEST ---> loss: 0.6325856447219849 auc: 0.5611285266457681 acc: 0.25217390060424805 mae: 0.16076846420764923, mse: 0.07700417190790176 rmse: 0.27749624848365784

TEST ---> loss: 0.566603422164917 auc: 0.5766129032258065 acc: 0.2530612349510193 mae: 0.15963466465473175, mse: 0.07620438933372498 rmse: 0.27605143189430237

TEST ---> loss: 0.6551538705825806 auc: 0.5820221218258296 acc: 0.2519230842590332 mae: 0.15960776805877686, mse: 0.07625506818294525 rmse: 0.2761431932449341

TEST ---> loss: 0.6857432126998901 auc: 0.5818181818181818 acc: 0.2454545497894287 mae: 0.15983469784259796, mse: 0.07658206671476364 rmse: 0.2767346501350403

TEST ---> loss: 0.6106315851211548 auc: 0.5898494414764449 acc: 0.24482758343219757 mae: 0.15929824113845825, mse: 0.07631947845220566 rmse: 0.27625980973243713

Global Metrics ---> average loss: [0.3053158] global auc: 0.5898494414764449 global acc: 0.23666666666666666 global mae: 0.15664326985677082 global mse: 0.07631947835286458 global rmse: 0.2762598022747149

