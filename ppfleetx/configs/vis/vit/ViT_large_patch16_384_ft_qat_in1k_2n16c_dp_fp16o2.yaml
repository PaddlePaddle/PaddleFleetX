_base_: ../base.yaml

Global:
  device: gpu
  seed: 2021

Engine:
  run_mode: 'epoch'
  num_train_epochs: 8
  eval_freq: 1
  accumulate_steps: 1
  logging_freq: 10
  mix_precision:
    enable: True
    scale_loss: 32768.0
    custom_black_list: ["reduce_sum", "elementwise_div"]
    custom_white_list: []
  save_load:
    save_epoch: 1
    output_dir: ./output
    ckpt_dir:

Distributed:
  dp_degree:

Model:
  module: "GeneralClsModule"
  model:
    name: "ViT_large_patch16_384"
    class_num: 1000
    drop_rate: 0.1
    pretrained:
      prefix_path: ./pretrained/vit/imagenet21k-ViT-L_16
      finetune: True
  loss:
    train:
      name: 'CELoss'
    eval:
      name: 'CELoss'
  metric:
    train:
      name: 'TopkAcc'
      topk: [1, 5]
    eval:
      name: 'TopkAcc'
      topk: [1, 5]

Optimizer:
  name: Momentum
  weight_decay: 0.0001
  momentum: 0.9
  lr:
    name: ViTLRScheduler
    learning_rate: 0.03
    decay_type: cosine
    warmup_steps: 500
  grad_clip:
    name: "ClipGradByGlobalNorm"
    clip_norm: 1.0


Data:
  Train:
    dataset:
      name: GeneralClsDataset
      image_root: ./dataset/ILSVRC2012/
      class_num: 1000
      cls_label_path: ./dataset/ILSVRC2012/train_list.txt
      transform_ops:
        - DecodeImage:
            to_rgb: True
            channel_first: False
        - RandCropImage:
            size: 384
            scale: [0.05, 1.0]
            interpolation: bilinear
            backend: pil
        - RandFlipImage:
            flip_code: 1
        - NormalizeImage:
            scale: 1.0/255.0
            mean: [0.5, 0.5, 0.5]
            std: [0.5, 0.5, 0.5]
            order: ''
        - ToCHWImage:

    sampler:
      name: DistributedBatchSampler
      batch_size: 32 # total batchsize 512
      drop_last: True
      shuffle: True
    loader:
      num_workers: 8
      use_shared_memory: True

  Eval:
    dataset: 
      name: GeneralClsDataset
      image_root: ./dataset/ILSVRC2012/
      cls_label_path: ./dataset/ILSVRC2012/val_list.txt
      transform_ops:
        - DecodeImage:
            to_rgb: True
            channel_first: False
        - ResizeImage:
            size: 384
            interpolation: bilinear
            backend: pil
        - NormalizeImage:
            scale: 1.0/255.0
            mean: [0.5, 0.5, 0.5]
            std: [0.5, 0.5, 0.5]
            order: ''
        - ToCHWImage:
        
    sampler:
      name: DistributedBatchSampler
      batch_size: 64
      drop_last: False
      shuffle: False
    loader:
      num_workers: 8
      use_shared_memory: True


Compress:
  Quantization:
    enable: True
    weight_quantize_type: 'channel_wise_abs_max'
    activation_quantize_type: 'moving_average_abs_max'
    activation_preprocess_type: 'PACT'
    weight_bits: 8
    activation_bits: 8
    onnx_format: True
