数据并行
=========

简介
~~~~~~~~~~~~~~

近年来，以GPU为代表的计算设备的算力大幅增长，这主要体现在以下两个方面：一方面，单个计算设备的算力逐年递增；另一方面，大规模计算集群使得集群整体算力急剧增长。单个设备算力的增长降低了同等复杂度问题的计算时间。然而，随着互联网和大数据技术的发展，可供模型训练的数据集极速扩增。例如，自然语言处理任务的数据集可达数TB。并且，模型规模也在不断增长。因此，模型训练的复杂度在持续增长，并且增长速度显著快于单个计算设备算力增长的速度。因此，单个设备完成模型训练的时间往往也变得更长。这时，就需要使用大规模计算集群和并行计算进一步加速训练。例如，使用2048张Tesla P40 GPU可以在4分钟内完成ImageNet训练[1]。

数据并行是深度学习领域最常用的并行方法。以工厂产品生产为例，我们可以训练数据比作生产产品的原材料，把训练一个mini-batch比作生产一件商品，把计算设备比作生产设备和工人。那么，单卡训练相当于只有一套生产设备和一个工人，工人每次从原材料中取出一份，经由生产设备的加工产出产品。然后，继续取出原材料进行加工生产，循环往复，直到完成生产任务。多卡分布式训练任务则相当于有多套生产设备和多个工人。这里，我们把单机多卡训练和多机多卡训练统一看作分布式训练，而不做特殊区分。那么，我们可以把原材料也分为多份。每个工人从分给自己的原材料中取出一份，经由生产设备的加工产出产品。然后，继续取出原材料进行加工生产，循环往复，直到完成生产任务。显然地，这里面存在两种情形：一种情形是，各个工人间独立生产，当其生产完一个产品时，即刻开始下一个产品的生产，而不需要考虑其它工人的生产状况，这相当于并行训练中的异步训练；另一种情形是，工人间需要相互协同，即当某个工人生产完一件产品后，其需要等待其他工人也完成产品的生产，然后才开始下一件产品的生产，这相当于并行训练中的同步训练。由于每个工人的熟练程度和生产设备的生产效率不同，因此各个工人生产产品的速度也必然存在差异。所以，在协同生产方式下，生产效率会降低。

同样地，同步训练的速度通常也低于异步训练。然而，同步训练在收敛性等方面往往由于异步训练，Collective架构分布式任务普遍采用同步训练的方式。因此，下文我们仅针对同步训练方式展开介绍。

原理介绍
~~~~~~~~~~~~~~

数据并行方式下，每个卡上保存完整的模型副本，并行处理多个数据。训练过程中，各个卡上的模型参数始终保持一致。如下图(a)所示。通常，训练数据集被切分为多份，各个卡独立处理一份数据集，采用这种并行方式，加速模型训练过程。

.. image:: ../img/data_parallel.png
  :width: 800
  :alt: Data Parallel
  :align: center

深度学习模型训练过程计算通常分为前向计算、反向计算和梯度更新。数据并行
方式下，为了保持各个卡上参数一致性，在初始阶段通过广播的方式将第一张卡
上的模型参数广播到其它所有卡。在反向计算阶段，各个卡独立计算梯度，并使
用AllReduce操作累加所有卡上的梯度并取平均。在参数更新阶段，使用梯度平均
值更新参数。如上图(b)所示。由于在初始阶段，各个卡上的参数一致，而在实际
训练阶段，使用各个卡上梯度均值更新参数，因此可以保证训练过程中各个卡的
参数始终保持一致。

数据并行训练主要包括以下两种方式。

1. 各个卡的批处理大小（batch size）和单卡训练保持一致。假设单卡的批处理
大小为B，数据并行训练使用的卡数为K。那么，数据并行方式下，单次迭代处理的
数据量为KB。在理想情形下，数据并行训练的吞吐量是单卡训练的K倍。但实际情形
下，由于分布式训练将引入额外的通信开销（即如前所述，获取各个卡上梯度值），因
此，数据并行训练相比于单卡训练的加速比通常小于K。

2. 分布式训练方式下，各个卡的批处理大小总和与单卡训练的批处理大小一致。那
么，分布式训练方式下，各个卡的批处理大小为B/K。因此，分布式训练方式下，每次
迭代的时间均明显小于单卡训练，从而在整体上提高训练吞吐量。


操作实践
~~~~~~~~~~~~~~

请参考\ `Collective训练快速开始 <../collective_quick_start.html>`_\ 获取如何使用Fleet API实现数据并行训练。

参考文献
~~~~~~~~~~~~~~

[1] `Highly Scalable Deep Learning Training System with Mixed-Precision: Training ImageNet in Four Minutes <https://arxiv.org/abs/1807.11205>`_