整体介绍与内容概览
==================

欢迎关注大规模深度学习技术
--------------------------

近十年来，深度学习技术不断刷新视觉、自然语言、语音、搜索、推荐等领域各种任务的记录。这其中的原因，用一个关键词描述就是“大规模”。大规模的数据使得模型有足够的知识可以记忆，大规模参数量的模型使得模型本身有能力记忆更多的数据，大规模高性能的算力（以GPU为典型代表）使得模型的训练速度有百倍甚至千倍的提升。数据、模型、算力的发展催生了大规模深度学习这个领域，如何进行多机任务的拆分、如何配置集群训练资源、如何平衡训练速度和收敛速度、如何训练单机无法训练的模型、弹性训练与容错等都是这个方向重点研究的问题。

飞桨分布式训练提供的核心价值
----------------------------

1. 源自产业实践的经验：

-  飞桨分布式训练技术源自百度的业务实践，是经过超大规模业务检验的训练框架。
-  飞桨分布式训练技术应用领域包括自然语言处理、计算机视觉、搜索和推荐等。

2. 完备的并行模式：

-  数据并行：针对产业界最常用的数据并行模式，飞桨基于实际业务需求重点打磨多项优化技术，提供集合通信架构和参数服务器架构两种方式，支持工业实践中常见的同步训练和异步训练机制，并提供收敛效果有保障的分布式优化算法。
-  Sharding并行：针对数据并行存在多份模型参数副本的问题，Sharding并行通过参数切分，确保模型参数在多个设备间只存在一个副本，降低数据并行的显存消耗，实现大规模模型训练。
-  流水线并行：增加模型深度（层数）是增加模型规模一种方式；流水线并行按层将模型拆分到不同计算设备并充分流水线化，实现高效的大规模模型训练。
-  张量模型并行：增加模型宽度（张量维度）是增加模型规模的另一种方式；张量模型并行将同一张量切分到不同计算设备，实现高效的大规模模型训练。
-  混合并行：针对超大规模模型训练，飞桨混合并行技术综合采用多种并行方式，充分利用机内和机间存储和带宽，实现高效的模型训练。

3. 面向云端场景的并行训练组件：

-  飞桨针对集群网络环境、硬件设备比较低配的场景提供多种实用的并行策略和优化算法。
-  针对云端算力具有弹性的特点，飞桨也始终在探索弹性深度学习的应用。

开始你的分布式训练之旅
----------------------

-  整体内容：我们推荐您直接根据\ `主页 <../index.html>`__\ ，按照章节顺序逐个浏览学习，如果有任何疑问都可以在\ `Paddle <https://github.com/PaddlePaddle/Paddle>`__\ 、\ `FleetX <https://github.com/PaddlePaddle/FleetX/>`__\ 提交issue提问。
-  FAQ：对于高频出现的问题，我们会定期整理相关内容到\ `FAQ <faq.html>`__\ 。
-  快速上手：如果想最低成本的了解飞桨的分布式训练，我们推荐阅读\ `GPU多机多卡(Collective)训练快速开始 <collective/collective_quick_start.html>`__\ 和\ `参数服务器训练快速开始 <parameter_server/ps_quick_start.html>`__\ 。
-  GPU多机训练：如果您已经开始使用GPU进行多机多卡训练，\ `Collective训练 <collective/index.html>`__\ 包含了诸多飞桨多机多卡的训练能力，建议阅读。
-  参数服务器：信息检索、推荐系统领域常用的并行训练方式，\ `参数服务器训练 <parameter_server/index.html>`__\ 包含了飞桨参数服务器的训练能力，建议阅读。
-  公有云环境实践：如果您在公有云上跑自己的GPU多卡任务，性能不佳，\ `优化低配网络的分布式GPU训练(DGC) <collective/collective_performance/communication_frequency.html>`__\ 是调优性能的好方法。
-  弹性训练：如果对如何利用云端弹性资源进行大规模蒸馏训练有兴趣，可以阅读\ `EDL服务型弹性蒸馏 <edl.html>`__\ 。

RoadMap
-------

-  敬请期待

