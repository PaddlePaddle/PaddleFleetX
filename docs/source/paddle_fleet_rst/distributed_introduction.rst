初始 不同并行模式: 数据并行、模型并行、流水线并行 不同实现架构:
集合通信架构、参数服务器架构 飞桨分布式训练 - 数据并行 -
模型并行、流水线并行 - 云端训练实践 - 性能Benchmark

初识分布式训练
==============

在大数据浪潮的推动下，有标签训练数据的规模取得了飞速的增长。现在人们通常用数百万甚至上千万的有标签图像来训练图像分类器（比如，ImageNet包含1400万幅图像，涵盖两万多个种类[1]），用成千上万小时的语音数据来训练语音模型（比如，Deep
Speech
2系统使用了11940小时的语音数据以及超过200万句表述来训练语音识别模型[2]）。在真实的业务场景中，训练数据的规模可以达到上述数据集的数十倍甚至数百倍，如此庞大的数据需要消耗大量的计算资源和训练时间使模型达到收敛状态（数天时间），因而对硬件提出了更高的要求。
从硬件角度，想要快速获得应用效果不错的模型，一种方式就是在单台服务器中使用计算能力更强的AI芯片；另一种方式就是采用多台服务器联合的分布式训练。
接下来了几篇文档主要围绕着飞桨的分布式训练能力展开。分布式训练是海量规模数据下提升训练效率最简单的手段，下图展示了基于飞桨框架1.8版本训练Resnet50模型在v100
GPU上多机多卡的训练吞吐扩展性，可以看出使用多卡训练可以大大提升训练的效率。

.. raw:: html

   <center>

.. raw:: html

   </center>

分布式训练进阶
==============

分布式训练的核心目的是加快模型的训练速度。通过对训练任务按照一定方法拆分分配到多个计算节点进行计算，再按照一定的方法对需要汇总的信息进行聚合，从而实现加快训练速度的目的。接下来我们分为分布式训练的并行方式和模型同步方式两个步骤对分布式训练进行简介。

分布式训练的并行方式
--------------------

在实际应用中，对训练任务的拆分方法是比较有限的，通常有如下几种：

-  数据并行：将数据集切分放到各计算节点，每个计算节点的计算内容完全一致，并在多个计算节点之间同步模型参数，我们通常称这种并行训练方法为数据并行。数据并行可以解决数据集过大无法在单机高效率训练的问题，也是工业生产中最常用的并行方法。

-  模型并行：通常指将模型单个算子计算分治到多个硬件设备上并发计算以达到计算单个算子计算速度的目的。我们一般会将单个算子的计算，利用模型并行的方式分配在配置相同的几个硬件上进行模型存储和计算，以保证计算步调一致。

-  流水线并行：一般是指将模型的不同算子，拆分到不同的硬件设备上进行计算，通过生产者-消费者的方式（流水线）完成不同设备之间的数据流通。深度学习中的跨设备交换数据场景很多，例如硬盘数据到内存，内存数据到显存，内存数据到网卡等，由于不同硬件之间处理数据的速度通常不一致，通常会采用流水线并行的方式进行训练效率最大化。

-  混合并行：在工业场景的实践中，分布式模型训练也会采用不同并行方式的组合，例如数据并行与模型并行结合，数据并行与流水线并行结合。

..

   说明：在实际应用中，数据并行的应用范围最广，像搜索、推荐领域的深度学习模型通常都是采用数据并行的方式进行切分的，也是飞桨最推荐用户使用的分布式训练方式。

   小结：数据并行->对训练数据进行切分；模型并行->对模型存储或者模型计算进行切分；流水并行->按照不同的硬件对模型进行切分；混合并行->多种切分方式混用

分布式训练中的模型同步方式
--------------------------

模型参数的同步是深度学习模型分布式训练中非常重要的一步，模型参数信息的同步方式、同步节奏等通常会直接影响模型的最终效果。下面我们会从模型参数同步的实现方法讲起，介绍两种常见的并行训练实现架构，即参数服务器架构、Collective架构。然后再介绍两种主流的模型参数同步方式，同步训练方式和异步训练方式。

**模型同步的常见架构**

中心化的参数服务器架构，采用将模型参数进行中心化管理的方式实现模型参数的同步。每个硬件设备在执行每一步训练时都可以向参数服务器发出请求来获取全局最新的模型参数，并基于最新的模型参数计算当前数据的模型梯度。当单个设备基于最新的模型参数进行模型梯度的计算后，可以将模型梯度发回给参数服务器。经典的参数服务器架构，通常是将神经网络模型的前向、后向放在设备中执行，模型的更新部分放在参数服务器一端。参数服务器架构通常可以对模型参数的存储进行分布式保存，因此对于存储超大规模模型参数的训练场景十分友好，比如个性化推荐任务中需要保存的海量稀疏特征对应的模型参数，通常就只能采用参数服务器架构才能实现。

去中心化的Collective架构是近年来非常流行的分布式训练架构，没有所谓管理模型参数的中心节点，每个训练节点都相当于掌握当前最新全局信息的中心，因此Collective架构通常也叫做去中心训练架构。在Collective架构中，多节点的参数同步通常是采用多次设备之间的点对点通信完成的，比较经典的通信算法比如\ `Baidu
Ring All
Reduce <https://github.com/baidu-research/baidu-allreduce>`__\ 可以采用较少的点对点通信轮数完成全局节点的模型参数同步。去中心化的Collective架构通常在现代高性能AI芯片中使用较多，这种架构对计算芯片的算力和芯片之间的网络互联要求较高。高性能计算的AI芯片例如\ `GPU <https://www.nvidia.com/en-us/data-center/v100/>`__\ ，芯片之间的高速网络互联例如\ `NVLINK <https://www.nvidia.com/en-us/data-center/nvlink/>`__,
`InfiniBand <https://en.wikipedia.org/wiki/InfiniBand>`__\ ，都加快的Collective训练架构的发展。Collective训练架构对于计算密集的任务非常友好，我们熟知的经典模型，例如机器翻译中的\ `Transformer <https://arxiv.org/abs/1706.03762>`__\ ，图像分类中的\ `Resnet50 <https://arxiv.org/abs/1512.03385>`__\ ，语音识别中的\ `DeepSpeech2 <https://arxiv.org/abs/1512.02595>`__\ 通常都是采用这种训练架构完成。

下图展示了Collective训练架构和参数服务器训练架构的示意图。

.. raw:: html

   <center>

.. raw:: html

   </center>

**同步并行训练算法**

同步并行训练通常是指在每个计算节点在模型训练的每一步都进行一次模型参数的全局更新，更新方式可以采用参数服务器架构，也可以采用Collective架构。同步训练在训练的每一步都会进行参数同步，因此其行为本质上与单机训练一致，只是单步训练的总数据量会更大。值得一提的是，在参数服务器架构下的同步训练，优化算法的执行是发生在参数服务器一端，而在Collective架构下，通过对每一步所有样本产生的模型参数梯度进行全局同步后，每个设备执行优化算法即相当于优化全局的模型参数。下图展示了单机SGD算法，基于Collective架构的同步SGD算法，基于Parameter
Server的异步SGD算法在计算步骤上的区别。可以看到Collective的架构发生通信的位置比较集中，并行是通过与正在训练的其他节点进行Collective通信完成，因此Collective架构是一种去中心化架构，每个节点只需要关注自己即可。参数服务器架构在获取参数，推送参数梯度等操作上都需要与参数服务器进行通信，参数服务器架构下的参数服务器端，要等待每个计算节点发送的梯度信息进行汇总后再进行模型参数的更新，因此是一种中心化的模式。

.. raw:: html

   <center>

.. raw:: html

   </center>

**异步并行训练算法**

异步并行训练在参数服务器架构下采用较多，其核心思想就是让每个计算节点不用关心其他节点的计算步调，独自与参数服务器完成模型参数的更新。异步并行训练情况下，参数服务器端的模型参数更新也是异步进行，即不需要等待其他正在计算的节点的进度。异步并行训练下，各个计算节点的计算节奏不同，参数服务器更新模型参数的节奏也会不同，这种特性使得模型的收敛可能存在一定的问题，能够保证高效率收敛的异步并行算法是一个算法研究比较多的领域。下图是一个单机SGD与参数服务器架构下的异步SGD的计算步骤对比，可以看到参数服务器一端与同步SGD的区别在于不需要对各个节点的梯度进行汇聚而直接进行模型参数的更新。

.. raw:: html

   <center>

.. raw:: html

   </center>

飞桨中的分布式训练
==================

飞桨（PaddlePaddle）是百度开源的一款深度学习框架，其中的分布式训练能力正是从百度众多大规模深度学习场景中打磨而成，可谓源自于百度的产业实践而成的深度学习框架。飞桨主推的分布式训练场景包括拥有超大规模数据、超大规模稀疏特征的搜索、推荐场景（参数服务器架构为主），也有依赖于海量数据的自然语言处理、计算机视觉领域中的经典模型（Collective架构为主），这些场景也是能够覆盖百度大规模业务的场景。此外，针对一些领域前沿的研究和特殊的应用需求，飞桨也支持经典的模型并行和流水线并行。

飞桨分布式API
-------------

尽管分布式训练能够大大提升用户在大规模数据下的模型训练速度，如前面背景知识的描述可知普通用户想快速掌握并行训练的方法并不容易，将飞桨的单机训练程序转换成多机训练程序会给用户带来一定的使用成本。为了降低用户使用分布式训练的门槛，飞桨官方支持分布式训练高级API
Fleet，作为分布式训练的统一入口API，用户可以在单机程序的基础上进行简单的几行代码修改即可实现多种类型的并行训练方式。在接下来的几篇教程中，我们会结合Fleet
API介绍飞桨数据并行方法在参数服务器架构和Collective架构下使用方法以及具体模型上的使用示例。

相关文档
--------

| 接下来的两篇文档主要围绕着飞桨核心的分布式训练能力展开介绍，我们结合Fleet
  API介绍飞桨的两个主流的并行训练场景：
| \* 参数服务器训练（参数服务器架构的数据并行）
| \* 多机多卡训练（Collective架构的数据并行）

参考文献
--------

-  [1][Deep Speech 2: End-to-End Speech Recognition in English and
   Mandarin](https://arxiv.org/pdf/1512.02595.pdf)
-  [2][Imagenet Dataset](http://www.image-net.org/)
